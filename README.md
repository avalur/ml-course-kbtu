# Machine learning course

 - **Course code: CSCI 5105**
 - **Number of credits: 3**
 - **Term: Fall 2022**

**Instructor's full name**: Ph.D in mathematical modelling, Associate Professor Alex Avdyushenko, https://github.com/avalur

Sat 16:00-19:00

[Telegram group for discussions and questions](https://t.me/+X2qjY_jLQeI3M2My)

**Course duration:** 45 classroom hours, 15 weeks: 3 hours a week

**Course objectives:**
The course introduces the concepts and techniques in machine learning and deep learning. The course will first introduce basics of machine learning such as statistical learning models, linear and logistic regression, SVM, Bayes classifier and ensemble. The course will then introduce the basics of deep learning which include multi-layer neural networks, stochastic gradient descent, backpropagation, and optimization techniques. It will also cover topics which include recurrent neural networks, convolutional neural networks, generative networks, NLP and deep reinforcement learning. Coursework will consist of a few programming assignments and a final project in Python and PyTorch.

**Knowledge:**

 - Understand basic concepts of machine learning and deep learning.
 - Understand several types of machine and deep learning such as logistic regression, SVM, CNN, RNN, Attentions, GAN, DQN and their applications
 - Acquire a working knowledge of implementing and training machine learning systems

**Skills:** Implement machine learning/deep learning applications using Python and
PyTorch

### Literature

**Required:** None (Hands-outs will be available)

**Supplementary:**

1. Pattern Recognition and Machine Learning, Christopher Bishop, 2006
https://goo.gl/EMbNKm
2. Introduction to Machine Learning, Ethem Alpaydin, 3rd Ed., 2014
3. Reinforcement Learning: An Introduction, Richard S. Sutton and Andrew G. Barto, 2020.
http://incompleteideas.net/book/RLbook2020.pdf
4. Deep Learning, Ian Goodfellow and Yoshua Bengio and Aaron Courville,
https://goo.gl/4kVPrm
5. Neural Networks and Deep Learning, Michael A. Nielsen, 2015,
http://neuralnetworksanddeeplearning.com/
6. Artificial Intelligence: A Modern Approach, Stuart Russell and Peter Norvig, 2020
7. (in Russian) Deep Learning: Dive into The World of Neural Networks, S.I. Nikolenko, A.A. Kadurin, E.O. Arkhangelskaya, Piter, 2017, https://logic.pdmi.ras.ru/~sergey/books.html

### Course calendar

**10.09, Lecture 1. Introduction to Machine Learning**

Course overview. Overview of machine learning and applications, K-NN. Python/Numpy Tutorial. Practice: K-NN

**17.09, Lecture 2. Regression**

Linear regression, Logistic regression and SGD. Practice: Linear/Logistic Regression

**24.09, Lecture 3. SVM and Bias-Variance**

Support Vector Machine (SVM), Bias-Variance. Practice: SVM


**01.10, Lecture 4. Bayesian Learning and Ensemble**

Naive Bayesian Classifier, Decision Tree, Ensemble. Practice: Bayesian Classifiers

----
**[08.10, Lecture 5. Perceptron, MLP and Backpropagation](https://github.com/avalur/ml-course-kbtu/tree/main/week05_nn_backprop)**

Perceptron, Softmax, Multi-Layer Perceptron (MLP), Multi-class Neural Networks, Backpropagation

Practice: Implementation of neural network with PyTorch for MNIST classification

<span style="color:green">
    Homework 1: SVM and Bayesian Classifiers
</span>

**[15.10, Lecture 6. CNN Basics](https://github.com/avalur/ml-course-kbtu/tree/main/week06_cnn_basics)**

Convolutional Neural Nets (CNN), Pooling, ImageNet

Practice: Implementation of fully-connected NN with NumPy for House numbers classification

**[24.10, Lecture 7. Optimization and Training Techniques](https://github.com/avalur/ml-course-kbtu/tree/main/week07_cnn_advanced)**

Regularization, Optimization, Normalization, Dropout

*Final Project Team Construct*

Practice: Implementation of convolutional NN with PyTorch for CIFAR10

<span style="color:green">
    Homework 2: Image classification competition ([Kaggle InClass](https://www.kaggle.com/t/6c13b4a6ee1e48729510c84c251adc59))
</span>

**29.10, Week 8: Midterm**

**05.11, Lecture 9: Recurrent Neural Networks (RNN)**

Backpropagation through time (BPTT), RNN, Long short-term memory (LSTM), Gated recurrent unit (GRU)

Practice: RNN with PyTorch

**12.11, Lecture 10: Attention, Transformers**

Attention Networks, Bidirectional Encoder Representations from Transformers (BERT)

Practice: Attention, Transformers

**19.11, Lecture 11: Autoencoder/VAE, GAN**

Autoencoder, Variational AutoEncoder (VAE), Self-Supervised Learning, Generative Adversarial Net (GAN)

Practice: Autoencoder/VAE, GAN

*Final Project Proposal: Team Idea presentation*

**26.11, Lecture 12: Intro to Reinforcement Learning (RL)**

Reinforcement Learning, Q-Learning, Deep Q-Learning Network (DQN) and Policy Gradients

Practice: RL examples

**03.12, Lecture 13: Final Project Presentation**

**10.12, Lecture 14: Final Project Presentation**

**17.12, Lecture 15: Final Exam**

**24.12, Lecture 16: Final Exam**

### Assessment criteria

<table>
    <thead>
        <tr>
            <th>#</th>
            <th>Assessment criteria</th>
            <th colspan=16>Weeks</th>
            <th>Total scores</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td colspan=2> </td>
            <td>1</td>
            <td>2</td>
            <td>3</td>
            <td>4</td>
            <td>5</td>
            <td>6</td>
            <td>7</td>
            <td>8</td>
            <td>9</td>
            <td>10</td>
            <td>11</td>
            <td>12</td>
            <td>13</td>
            <td>14</td>
            <td>15</td>
            <td>16</td>
            <td> </td>
        </tr>
        <tr>
            <td>1.</td>
            <td>Midterm</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>8</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>20%</td>
        </tr>
        <tr>
            <td>2.</td>
            <td>Two Homeworks</td>
            <td> </td>
            <td> </td>
            <td>3</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>7</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>20%</td>
        </tr>
        <tr>
            <td>3.</td>
            <td>Final Project</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>7</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>13</td>
            <td>14</td>
            <td> </td>
            <td> </td>
            <td>25%</td>
        </tr>
        <tr>
            <td>4.</td>
            <td>Final Exam</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>7</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>15</td>
            <td>16</td>
            <td>25%</td>
        </tr>
        <tr>
            <td>5.</td>
            <td>Class Participation</td>
            <td>1</td>
            <td>2</td>
            <td>3</td>
            <td>4</td>
            <td>5</td>
            <td>6</td>
            <td>7</td>
            <td>8</td>
            <td>9</td>
            <td>10</td>
            <td>11</td>
            <td>12</td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td> </td>
            <td>10%</td>
        </tr>
        <tr>
            <td> </td>
            <th>Total</th>
            <th colspan=16> </th>
            <th>100%</th>
        </tr>
    </tbody>
</table>


### Homework and Programming Assignments
Students are encouraged to discuss assignments with other students, both to share high-level understanding of the design or basic utilities, However, coding and writing of Homeworks must be done individually or by a team submitting as a group. 

### [Final Project](https://github.com/avalur/ml-course-kbtu/tree/main/paper_post.md)

### Final Exam
TBD

*Instructor Alex A*
